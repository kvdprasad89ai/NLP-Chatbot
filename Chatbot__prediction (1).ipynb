{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot _prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0204EJTO3D6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "15563463-ae6a-468e-a22d-a8658d632b2b"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from keras.models import Model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6nH4UNB3Hat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "\n",
        "def in_white_list(_word):\n",
        "  '''Check if the characters in the words are whitelisted'''\n",
        "  for char in _word:\n",
        "      if char in WHITELIST:\n",
        "          return True\n",
        "\n",
        "  return False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eeq3WCuh3PCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Load dictionary values from  glove.twitter.27B.100d.txt file.\n",
        "Add embedded values into wrd2embedding dictionary.\n",
        "'''\n",
        "word2embedding = None\n",
        "file_path = \"/content/drive/My Drive/NLP Chatbot\"\n",
        "\n",
        "def load_glove_twitter_data():\n",
        "    _word2embedding = {}\n",
        "    file = open(file_path+\"/embedding_data/glove.twitter.27B.100d.txt\", mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        words = line.strip().split()\n",
        "        word = words[0]\n",
        "        embeds = np.array(words[1:], dtype=np.float32)\n",
        "        _word2embedding[word] = embeds        \n",
        "    file.close()\n",
        "    return _word2embedding\n",
        "word2embedding = load_glove_twitter_data()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT-NsVjH4eXs",
        "colab_type": "text"
      },
      "source": [
        "**Load word to index and index to word information from saved mpy files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYd3b3v-4URy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_word2idx = None\n",
        "target_idx2word = None\n",
        "max_decoder_seq_length = None\n",
        "max_encoder_seq_length = None\n",
        "num_decoder_tokens = None\n",
        "\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "\n",
        "target_word2idx = np.load( file_path + '/word-glove-target-word2idx.npy',allow_pickle=True).item()\n",
        "target_idx2word = np.load( file_path + '/word-glove-target-idx2word.npy',allow_pickle=True).item()\n",
        "context = np.load( file_path + '/word-glove-context.npy',allow_pickle=True).item()\n",
        "\n",
        "max_encoder_seq_length = context['encoder_max_seq_length']\n",
        "max_decoder_seq_length = context['decoder_max_seq_length']\n",
        "num_decoder_tokens = context['num_decoder_tokens']\n",
        "\n",
        "'''\n",
        "Preparing encoder inputs with defining  glove embedding size and number ond number of hudden units.\n",
        "These number should be same as what we train our LSTM mode.\n",
        "'''\n",
        "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "\n",
        "'''\n",
        "Preparing decoder inputs with defining  glove embedding size and number ond number of hudden units.\n",
        "These number should be same as what we train our LSTM mode.\n",
        "'''\n",
        "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f64keFv9618m",
        "colab_type": "text"
      },
      "source": [
        "**Prepare model object by passing encode and decoder inputs paramater.\n",
        "\n",
        "Load train LSTM model for loading weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIh3_Gbn6zwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.load_weights( file_path + '/word-glove-weights.h5')\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huGUY3VB7xFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bLwy4iG8BPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reply(input_text):\n",
        "  input_seq = []\n",
        "  input_emb = []\n",
        "  for word in nltk.word_tokenize(input_text.lower()):\n",
        "    print(word)\n",
        "    if not in_white_list(word):\n",
        "      continue\n",
        "    \n",
        "    emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "    if word in word2embedding:\n",
        "      emb = word2embedding[word]\n",
        "    input_emb.append(emb)\n",
        "  \n",
        "  #print(input_emb)\n",
        "  input_seq.append(input_emb)\n",
        "  input_seq = pad_sequences(input_seq, max_encoder_seq_length)\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "  target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "  target_seq[0, 0, :] = word2embedding['start']\n",
        "  target_text = ''\n",
        "  target_text_len = 0\n",
        "  terminated = False\n",
        "  while not terminated:\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "    sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "    sample_word = target_idx2word[sample_token_idx]\n",
        "    target_text_len += 1\n",
        "\n",
        "    if sample_word != 'start' and sample_word != 'end':\n",
        "      target_text += ' ' + sample_word\n",
        "\n",
        "    if sample_word == 'end' or target_text_len >= max_decoder_seq_length:\n",
        "      terminated = True\n",
        "\n",
        "    target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "    if sample_word in word2embedding:\n",
        "      target_seq[0, 0, :] = word2embedding[sample_word]\n",
        "    states_value = [h, c]\n",
        "\n",
        "  return target_text.strip()\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyhTEMqX9OLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "f99275cc-f5ae-4629-aded-6fb85f5762b5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "print(reply('Hello'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "hello\n",
            "'' i 'm a unknown of unknown unknown unknown unknown of the unknown of unknown unknown unknown of the unknown of unknown unknown unknown of the unknown of unknown unknown unknown of the unknown of unknown unknown unknown unknown unknown unknown\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80BVT2juC3kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b3c03501-060a-49e4-a738-0df3c3d670f2"
      },
      "source": [
        "print(reply(\"Good evening\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "good\n",
            "evening\n",
            "i 'm sorry . i 'm going to be a unknown of unknown unknown of the unknown of unknown unknown of the unknown of unknown unknown of the unknown of unknown unknown of the unknown of unknown unknown unknown of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMcITwNQDtft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b8f66c12-576b-494f-ec5f-e03e39c2a245"
      },
      "source": [
        "print(reply('Jungle man fix'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jungle\n",
            "man\n",
            "fix\n",
            "i 'm sorry . i 'm going to be a unknown of unknown unknown . i 'm not going to be a unknown of unknown unknown of the unknown of unknown unknown of the unknown of unknown unknown unknown of\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTSLRQ1I4l-6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}